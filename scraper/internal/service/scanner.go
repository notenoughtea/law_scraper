package service

import (
    "bytes"
    "errors"
    "io"
    "net/http"
    "net/url"
    "path"
    "regexp"
    "strings"
    "unicode/utf8"
    "archive/zip"
    "encoding/xml"
    "fmt"

    "github.com/notenoughtea/law_scraper/internal/clients"
    "github.com/notenoughtea/law_scraper/internal/logger"
    "github.com/notenoughtea/law_scraper/internal/repository"
)

var attachmentRe = regexp.MustCompile(`href="([^"]+\.(?:pdf|txt|docx|doc))"`)
var projIDRe = regexp.MustCompile(`/projects/(\d+)`)

func absoluteLink(base string, href string) string {
    u, err := url.Parse(href)
    if err != nil {
        return href
    }
    if u.IsAbs() {
        return href
    }
    bu, err := url.Parse(base)
    if err != nil {
        return href
    }
    // join relative
    bu.Path = path.Join(bu.Path, u.Path)
    return bu.String()
}

func fetch(url string) ([]byte, error) {
    req, err := http.NewRequest("GET", url, nil)
    if err != nil {
        return nil, err
    }
    req.Header.Set("Accept", "*/*")
    resp, err := http.DefaultClient.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    if resp.StatusCode < 200 || resp.StatusCode >= 300 {
        return nil, errors.New(resp.Status)
    }
    return io.ReadAll(resp.Body)
}

func isMostlyPrintable(s string) bool {
    if len(s) == 0 { return false }
    total := 0
    printable := 0
    for _, r := range s {
        total++
        if r == '\n' || r == '\r' || r == '\t' || (r >= 32 && r < 127) || (r >= 0x0400 && r <= 0x04FF) {
            printable++
        }
    }
    return printable*100/total >= 80
}

// extractDocxText –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOCX (word/document.xml) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ UTF-8
func extractDocxText(data []byte) (string, error) {
    zr, err := zip.NewReader(bytes.NewReader(data), int64(len(data)))
    if err != nil {
        return "", err
    }
    var r io.ReadCloser
    for _, f := range zr.File {
        if f.Name == "word/document.xml" {
            rc, err := f.Open()
            if err != nil {
                return "", err
            }
            r = rc
            break
        }
    }
    if r == nil {
        return "", fmt.Errorf("document.xml not found")
    }
    defer r.Close()
    dec := xml.NewDecoder(r)
    var b strings.Builder
    inText := false
    for {
        tok, err := dec.Token()
        if err == io.EOF {
            break
        }
        if err != nil {
            return "", err
        }
        switch t := tok.(type) {
        case xml.StartElement:
            if t.Name.Local == "t" { // w:t
                inText = true
            }
        case xml.EndElement:
            if t.Name.Local == "t" {
                inText = false
                b.WriteByte(' ')
            }
        case xml.CharData:
            if inText {
                b.WriteString(string(t))
            }
        }
    }
    return strings.ToLower(b.String()), nil
}

// decodeWindows1251 –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç –±–∞–π—Ç—ã cp1251 –≤ —Å—Ç—Ä–æ–∫—É UTF-8
func decodeWindows1251(b []byte) string {
    // –¢–∞–±–ª–∏—Ü–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π 0x80-0xFF ‚Üí Unicode (cp1251)
    var cp1251 = [128]rune{
        0x0402, 0x0403, 0x201A, 0x0453, 0x201E, 0x2026, 0x2020, 0x2021,
        0x20AC, 0x2030, 0x0409, 0x2039, 0x040A, 0x040C, 0x040B, 0x040F,
        0x0452, 0x2018, 0x2019, 0x201C, 0x201D, 0x2022, 0x2013, 0x2014,
        0x00,   0x2122, 0x0459, 0x203A, 0x045A, 0x045C, 0x045B, 0x045F,
        0x00A0, 0x040E, 0x045E, 0x0408, 0x00A4, 0x0490, 0x00A6, 0x00A7,
        0x0401, 0x00A9, 0x0404, 0x00AB, 0x00AC, 0x00AD, 0x00AE, 0x0407,
        0x00B0, 0x00B1, 0x0406, 0x0456, 0x0491, 0x00B5, 0x00B6, 0x00B7,
        0x0451, 0x2116, 0x0454, 0x00BB, 0x0458, 0x0405, 0x0455, 0x0457,
        0x0410, 0x0411, 0x0412, 0x0413, 0x0414, 0x0415, 0x0416, 0x0417,
        0x0418, 0x0419, 0x041A, 0x041B, 0x041C, 0x041D, 0x041E, 0x041F,
        0x0420, 0x0421, 0x0422, 0x0423, 0x0424, 0x0425, 0x0426, 0x0427,
        0x0428, 0x0429, 0x042A, 0x042B, 0x042C, 0x042D, 0x042E, 0x042F,
        0x0430, 0x0431, 0x0432, 0x0433, 0x0434, 0x0435, 0x0436, 0x0437,
        0x0438, 0x0439, 0x043A, 0x043B, 0x043C, 0x043D, 0x043E, 0x043F,
        0x0440, 0x0441, 0x0442, 0x0443, 0x0444, 0x0445, 0x0446, 0x0447,
        0x0448, 0x0449, 0x044A, 0x044B, 0x044C, 0x044D, 0x044E, 0x044F,
    }
    out := make([]rune, 0, len(b))
    for _, by := range b {
        if by < 0x80 {
            out = append(out, rune(by))
        } else {
            r := cp1251[by-0x80]
            if r == 0x00 {
                // –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∏–º–≤–æ–ª ‚Äì –ø—Ä–æ–ø—É—Å—Ç–∏–º
                continue
            }
            out = append(out, r)
        }
    }
    return strings.ToLower(string(out))
}

// decodeToLowerUTF8 –ø—ã—Ç–∞–µ—Ç—Å—è –≤–µ—Ä–Ω—É—Ç—å —Ç–µ–∫—Å—Ç –≤ UTF-8 (–Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä):
// - –µ—Å–ª–∏ –≤—Ö–æ–¥ –≤–∞–ª–∏–¥–µ–Ω –∫–∞–∫ UTF-8 ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ;
// - –∏–Ω–∞—á–µ –ø—Ä–æ–±—É–µ–º cp1251 ‚Üí UTF-8.
func decodeToLowerUTF8(b []byte) string {
    if utf8.Valid(b) {
        return strings.ToLower(string(b))
    }
    return decodeWindows1251(b)
}

type Match struct {
    ProjectURL  string   `json:"projectUrl"`
    FileURL     string   `json:"fileUrl"`
    Keywords    []string `json:"keywords"`
    PubDate     string   `json:"pubDate"`     // –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏–∑ RSS
    Title       string   `json:"title"`       // –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ RSS
    Description string   `json:"description"` // –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑ RSS
}

func ScanRSSAndProjects(rssURL string) ([]Match, error) {
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π RSS –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    logger.Log.Info("–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ RSS –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è...")
    oldFeed, err := repository.LoadPreviousRSS()
    if err != nil {
        logger.Log.Warnf("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π RSS: %v", err)
    }
    
    // –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π RSS
    feed, err := clients.FetchRSS(rssURL)
    if err != nil {
        return nil, err
    }
    logger.Log.Infof("RSS –∑–∞–≥—Ä—É–∂–µ–Ω: %d —ç–ª–µ–º–µ–Ω—Ç–æ–≤", len(feed.Channel.Items))
    
    // –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
    newItems := repository.GetNewRSSItems(feed, oldFeed)
    
    if len(newItems) == 0 {
        logger.Log.Info("‚úì –ù–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ RSS –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        return []Match{}, nil
    }
    
    logger.Log.Infof("üÜï –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: %d", len(newItems))
    
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π RSS –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞
    if err := repository.SaveRSS(feed); err != nil {
        return nil, err
    }
    logger.Log.Info("RSS —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")

    keywords := repository.LoadKeywords()
    for i := range keywords {
        keywords[i] = strings.ToLower(keywords[i])
    }
    logger.Log.Infof("–ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: %v", keywords)

    var matches []Match
    for _, it := range newItems {
        pageURL := it.Link
        html, err := fetch(pageURL)
        if err != nil {
            logger.Log.Warnf("–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã %s: %v", pageURL, err)
            continue
        }
        lowerHTML := strings.ToLower(string(html))

        // 1) –∏—Å–∫–∞—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø—Ä—è–º–æ –≤ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        var foundPage []string
        for _, kw := range keywords {
            if kw == "" { continue }
            if strings.Contains(lowerHTML, kw) {
                foundPage = append(foundPage, kw)
            }
        }
        if len(foundPage) > 0 {
            matches = append(matches, Match{
                ProjectURL:  pageURL, 
                FileURL:     pageURL, 
                Keywords:    foundPage,
                PubDate:     it.PubDate,
                Title:       it.Title,
                Description: it.Description,
            })
        }

        // 2) –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±: –ø–æ–ª—É—á–∏—Ç—å ID —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ GetProjectStages/{id}
        var projectID string
        if m := projIDRe.FindStringSubmatch(pageURL); len(m) == 2 {
            projectID = m[1]
        }
        if projectID != "" {
            stagesURL := "https://regulation.gov.ru/api/public/PublicProjects/GetProjectStages/" + projectID
            ids, err := clients.FetchProjectStagesFileIDs(stagesURL)
            if err != nil {
                logger.Log.Warnf("–æ—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–¥–∏–π –ø—Ä–æ–µ–∫—Ç–∞ %s: %v", projectID, err)
            } else {
                for _, fid := range ids {
                    fileURL := "https://regulation.gov.ru/api/public/Files/GetFile/" + fid
                    data, err := fetch(fileURL)
                    if err != nil {
                        logger.Log.Warnf("–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–ª–æ–∂–µ–Ω–∏—è %s: %v", fileURL, err)
                        continue
                    }
                    // –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ DOCX; –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç
                    var textLower string
                    if txt, err := extractDocxText(data); err == nil && txt != "" {
                        textLower = txt
                    } else {
                        textLower = decodeToLowerUTF8(data)
                    }
                    // –õ–æ–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
                    if isMostlyPrintable(textLower) {
                        logger.Log.Infof("—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ (utf-8):\n%s", textLower)
                    } else {
                        logger.Log.Infof("—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞: –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–ª–∏ –Ω–µ—á–∏—Ç–∞–µ–º–æ–µ, —Ç–µ–∫—Å—Ç –æ–ø—É—â–µ–Ω")
                    }
                    lower := []byte(textLower)
                    var found []string
                    for _, kw := range keywords {
                        if kw == "" { continue }
                        if bytes.Contains(lower, []byte(kw)) {
                            logger.Log.Infof("—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ª–æ–≤–∞: —Ñ–∞–π–ª=%s, —Å–ª–æ–≤–æ='%s' -> –Ω–∞–π–¥–µ–Ω–æ", fileURL, kw)
                            found = append(found, kw)
                        } else {
                            logger.Log.Infof("—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ª–æ–≤–∞: —Ñ–∞–π–ª=%s, —Å–ª–æ–≤–æ='%s' -> –Ω–µ—Ç", fileURL, kw)
                        }
                    }
                    if len(found) > 0 {
                        logger.Log.Infof("—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ª–æ–≤: —Ñ–∞–π–ª=%s, –Ω–∞–π–¥–µ–Ω–æ=%v", fileURL, found)
                        matches = append(matches, Match{
                            ProjectURL:  pageURL, 
                            FileURL:     fileURL, 
                            Keywords:    found,
                            PubDate:     it.PubDate,
                            Title:       it.Title,
                            Description: it.Description,
                        })
                    } else {
                        logger.Log.Infof("—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ª–æ–≤: —Ñ–∞–π–ª=%s, —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Ç", fileURL)
                    }
                }
            }
		}
	}
	
	// –°–æ–±—Ä–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ URL-–æ–≤ —Ñ–∞–π–ª–æ–≤ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
	fileURLs := make([]repository.FileURLWithKeywords, 0)
	for _, m := range matches {
		if m.FileURL != m.ProjectURL {
			// –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ URL-—ã —Ñ–∞–π–ª–æ–≤, –∞ –Ω–µ —Å—Ç—Ä–∞–Ω–∏—Ü –ø—Ä–æ–µ–∫—Ç–æ–≤
			fileURLs = append(fileURLs, repository.FileURLWithKeywords{
				URL:         m.FileURL,
				Keywords:    m.Keywords,
				PubDate:     m.PubDate,
				Title:       m.Title,
				Description: m.Description,
			})
		}
	}
	if len(fileURLs) > 0 {
		if err := repository.SaveFileURLs(fileURLs); err != nil {
			logger.Log.Warnf("–Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ URL-–æ–≤ —Ñ–∞–π–ª–æ–≤: %v", err)
		} else {
			logger.Log.Infof("—Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å–ø–∏—Å–æ–∫ –∏–∑ %d URL-–æ–≤ —Ñ–∞–π–ª–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏", len(fileURLs))
		}
	}
	
	return matches, nil
}


