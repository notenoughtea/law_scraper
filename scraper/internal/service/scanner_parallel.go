package service

import (
	"bytes"
	"encoding/json"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/notenoughtea/law_scraper/internal/clients"
	"github.com/notenoughtea/law_scraper/internal/config"
	"github.com/notenoughtea/law_scraper/internal/logger"
	"github.com/notenoughtea/law_scraper/internal/repository"
)

var (
	// –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Ñ–∞–π–ª–æ–≤
	// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 3 –¥–ª—è —Å–ª–∞–±–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ (768MB RAM, 1 CPU)
	// –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —á–µ—Ä–µ–∑ config.GetMaxWorkers()
	maxWorkers = 3
)

func init() {
	// –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
	maxWorkers = getMaxWorkers()
}

// getMaxWorkers –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
func getMaxWorkers() int {
	if workers := config.GetMaxWorkers(); workers > 0 {
		return workers
	}
	// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 3 –≤–æ—Ä–∫–µ—Ä–∞ –¥–ª—è —Å–ª–∞–±–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
	return 3
}

// fileTask –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
type fileTask struct {
	fileURL     string
	projectURL  string
	projectID   string
	pubDate     string
	title       string
	description string
	keywords    []string
}

// ScanRSSAndProjectsParallel –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –æ—Ç–ø—Ä–∞–≤–∫–æ–π —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π —Å—Ä–∞–∑—É
// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
func ScanRSSAndProjectsParallel(rssURL string) (int, error) {
	// –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π RSS –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
	logger.Log.Info("–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ RSS –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è...")
	oldFeed, err := repository.LoadPreviousRSS()
	if err != nil {
		logger.Log.Warnf("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π RSS: %v", err)
	}

	// –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π RSS
	feed, err := clients.FetchRSS(rssURL)
	if err != nil {
		return 0, err
	}
	logger.Log.Infof("RSS –∑–∞–≥—Ä—É–∂–µ–Ω: %d —ç–ª–µ–º–µ–Ω—Ç–æ–≤", len(feed.Channel.Items))

	// –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
	newItems := repository.GetNewRSSItems(feed, oldFeed)

	if len(newItems) == 0 {
		logger.Log.Info("‚úì –ù–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ RSS –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
		return 0, nil
	}

	logger.Log.Infof("üÜï –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: %d", len(newItems))

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π RSS –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞
	if err := repository.SaveRSS(feed); err != nil {
		return 0, err
	}
	logger.Log.Info("RSS —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")

	keywords := repository.LoadKeywords()
	for i := range keywords {
		keywords[i] = strings.ToLower(keywords[i])
	}
	logger.Log.Infof("–ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: %v", keywords)

	// –ö–∞–Ω–∞–ª –¥–ª—è –∑–∞–¥–∞—á –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–æ–≤
	tasksChan := make(chan fileTask, 100)

	// WaitGroup –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –≤–æ—Ä–∫–µ—Ä–æ–≤
	var wg sync.WaitGroup

	// –°—á–µ—Ç—á–∏–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
	var matchesCount int64
	var matchesMutex sync.Mutex

	// –ó–∞–ø—É—Å–∫–∞–µ–º –≤–æ—Ä–∫–µ—Ä—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go fileWorker(i+1, tasksChan, keywords, &wg, &matchesCount, &matchesMutex)
	}

	// –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ (—Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏)
	totalTasks := 0

	// –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –Ω–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç RSS
	for _, it := range newItems {
		pageURL := it.Link
		html, err := fetch(pageURL)
		if err != nil {
			logger.Log.Warnf("–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã %s: %v", pageURL, err)
			continue
		}
		lowerHTML := strings.ToLower(string(html))

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
		var foundPage []string
		for _, kw := range keywords {
			if kw == "" {
				continue
			}
			if strings.Contains(lowerHTML, kw) {
				foundPage = append(foundPage, kw)
			}
		}

		if len(foundPage) > 0 {
			// –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ä–∞–∑—É
			logger.Log.Infof("‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ %s: %v", pageURL, foundPage)
			sendNotificationImmediately(pageURL, pageURL, foundPage, it.PubDate, it.Title, it.Description, &matchesCount, &matchesMutex)
		}

		// –ü–æ–ª—É—á–∞–µ–º ID –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
		var projectID string
		if m := projIDRe.FindStringSubmatch(pageURL); len(m) == 2 {
			projectID = m[1]
		}

		if projectID != "" {
			stagesURL := "https://regulation.gov.ru/api/public/PublicProjects/GetProjectStages/" + projectID
			ids, err := clients.FetchProjectStagesFileIDs(stagesURL)
			if err != nil {
				logger.Log.Warnf("–æ—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–¥–∏–π –ø—Ä–æ–µ–∫—Ç–∞ %s: %v", projectID, err)
				continue
			}

			// –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–æ–≤
			for _, fid := range ids {
				fileURL := "https://regulation.gov.ru/api/public/Files/GetFile/" + fid
				tasksChan <- fileTask{
					fileURL:     fileURL,
					projectURL:  pageURL,
					projectID:   projectID,
					pubDate:     it.PubDate,
					title:       it.Title,
					description: it.Description,
				}
				totalTasks++
			}
		}
	}

	// –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–∞–Ω–∞–ª –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤—Å–µ—Ö –∑–∞–¥–∞—á
	close(tasksChan)
	logger.Log.Infof("üìã –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: %d", totalTasks)

	// –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤
	wg.Wait()

	matchesMutex.Lock()
	count := int(matchesCount)
	matchesMutex.Unlock()

	logger.Log.Infof("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: %d", count)

	return count, nil
}

// fileWorker –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª—ã –∏–∑ –∫–∞–Ω–∞–ª–∞ –∑–∞–¥–∞—á
func fileWorker(workerID int, tasksChan <-chan fileTask, keywords []string, wg *sync.WaitGroup, matchesCount *int64, matchesMutex *sync.Mutex) {
	defer wg.Done()

	for task := range tasksChan {
		logger.Log.Infof("üë∑ –í–æ—Ä–∫–µ—Ä %d –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª: %s", workerID, task.fileURL)

		// –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
		data, err := fetch(task.fileURL)
		if err != nil {
			logger.Log.Warnf("–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–ª–æ–∂–µ–Ω–∏—è %s: %v", task.fileURL, err)
			continue
		}

		// –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
		var textLower string
		if txt, err := extractDocxText(data); err == nil && txt != "" {
			textLower = txt
		} else {
			textLower = decodeToLowerUTF8(data)
		}

		// –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
		lower := []byte(textLower)
		var found []string
		for _, kw := range keywords {
			if kw == "" {
				continue
			}
			if bytes.Contains(lower, []byte(kw)) {
				found = append(found, kw)
			}
		}

		// –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å—Ä–∞–∑—É
		if len(found) > 0 {
			logger.Log.Infof("‚úÖ –í–æ—Ä–∫–µ—Ä %d: –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª–µ %s: %v", workerID, task.fileURL, found)
			sendNotificationImmediately(task.projectURL, task.fileURL, found, task.pubDate, task.title, task.description, matchesCount, matchesMutex)
		} else {
			logger.Log.Debugf("–í–æ—Ä–∫–µ—Ä %d: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ñ–∞–π–ª–µ %s", workerID, task.fileURL)
		}

		// –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
		time.Sleep(100 * time.Millisecond)
	}

	logger.Log.Infof("üë∑ –í–æ—Ä–∫–µ—Ä %d –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É", workerID)
}

// sendNotificationImmediately –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
func sendNotificationImmediately(projectURL, fileURL string, keywords []string, pubDate, title, description string, matchesCount *int64, matchesMutex *sync.Mutex) {
	// –õ–æ–≥–∏—Ä—É–µ–º —á—Ç–æ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è
	logger.Log.Infof("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è %s", fileURL)
	logger.Log.Infof("   –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: %v (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: %d)", keywords, len(keywords))
	logger.Log.Infof("   –ó–∞–≥–æ–ª–æ–≤–æ–∫: %s", title)

	// –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ keywords –ø—É—Å—Ç–æ–π, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
	if len(keywords) == 0 {
		logger.Log.Warnf("‚ö†Ô∏è  –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø—É—Å—Ç—ã–µ –¥–ª—è —Ñ–∞–π–ª–∞ %s! –≠—Ç–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å.", fileURL)
	}

	// –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
	matchesMutex.Lock()
	*matchesCount++
	count := *matchesCount
	matchesMutex.Unlock()

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
	if fileURL != projectURL {
		// –¢–æ–ª—å–∫–æ –¥–ª—è —Ñ–∞–π–ª–æ–≤, –Ω–µ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü
		fileData := repository.FileURLWithKeywords{
			URL:         fileURL,
			ProjectURL:  projectURL,
			Keywords:    keywords,
			PubDate:     pubDate,
			Title:       title,
			Description: description,
		}

		// –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ñ–∞–π–ª (–∞–ø–ø–µ–Ω–¥) - —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç race condition
		appendToFileURLs(fileData)
	}

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å—Ä–∞–∑—É
	if err := clients.SendFileURLWithKeywords(projectURL, fileURL, keywords, pubDate, title, description); err != nil {
		logger.Log.Errorf("‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è %s: %v", fileURL, err)
	} else {
		logger.Log.Infof("‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ #%d –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –¥–ª—è %s (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: %v)", count, fileURL, keywords)
	}
}

// appendToFileURLs –¥–æ–±–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –≤ —Å–ø–∏—Å–æ–∫ (–¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏)
// –ò—Å–ø–æ–ª—å–∑—É–µ—Ç mutex –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç race condition
var fileURLsMutex sync.Mutex

func appendToFileURLs(file repository.FileURLWithKeywords) {
	fileURLsMutex.Lock()
	defer fileURLsMutex.Unlock()

	// –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–ø–∏—Å–æ–∫
	existing, _ := loadFileURLs()

	// –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª
	existing = append(existing, file)

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ
	if err := repository.SaveFileURLs(existing); err != nil {
		logger.Log.Warnf("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ URL-–æ–≤ —Ñ–∞–π–ª–æ–≤: %v", err)
	}
}

// loadFileURLs –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑ JSON
func loadFileURLs() ([]repository.FileURLWithKeywords, error) {
	filePath := filepath.Join(config.GetMatchedDir(), "file_urls.json")
	data, err := os.ReadFile(filePath)
	if err != nil {
		if os.IsNotExist(err) {
			return []repository.FileURLWithKeywords{}, nil
		}
		return nil, err
	}

	var files []repository.FileURLWithKeywords
	if err := json.Unmarshal(data, &files); err != nil {
		return nil, err
	}

	return files, nil
}
